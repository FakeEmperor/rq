# -*- coding: utf-8 -*-
#
# Copyright 2020 NVIDIA Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import datetime
import logging
from logging import Logger

from redis.client import Pipeline, Redis

from . import worker_registration as worker_registration
from .compat import PY2 as PY2, as_text as as_text, string_types as string_types, text_type as text_type
from .connections import (
    get_current_connection as get_current_connection,
    pop_connection as pop_connection,
    push_connection as push_connection,
    Connection,
)
from .defaults import (
    DEFAULT_JOB_MONITORING_INTERVAL as DEFAULT_JOB_MONITORING_INTERVAL,
    DEFAULT_LOGGING_DATE_FORMAT as DEFAULT_LOGGING_DATE_FORMAT,
    DEFAULT_LOGGING_FORMAT as DEFAULT_LOGGING_FORMAT,
    DEFAULT_RESULT_TTL as DEFAULT_RESULT_TTL,
    DEFAULT_WORKER_TTL as DEFAULT_WORKER_TTL,
)
from .exceptions import DequeueTimeout as DequeueTimeout, ShutDownImminentException as ShutDownImminentException
from .job import Job as Job, JobStatus as JobStatus
from .logutils import setup_loghandlers as setup_loghandlers
from .queue import Queue as Queue
from .registry import (
    FailedJobRegistry as FailedJobRegistry,
    StartedJobRegistry as StartedJobRegistry,
    clean_registries as clean_registries,
)
from .scheduler import RQScheduler as RQScheduler
from .serializers import resolve_serializer as resolve_serializer, DefaultSerializer
from .suspension import is_suspended as is_suspended
from .timeouts import (
    HorseMonitorTimeoutException as HorseMonitorTimeoutException,
    JobTimeoutException as JobTimeoutException,
    UnixSignalDeathPenalty as UnixSignalDeathPenalty,
    BaseDeathPenalty,
)
from .utils import (
    backend_class as backend_class,
    ensure_list as ensure_list,
    enum as enum,
    make_colorizer as make_colorizer,
    utcformat as utcformat,
    utcnow as utcnow,
    utcparse as utcparse,
)
from .version import VERSION as VERSION
from .worker_registration import clean_worker_registry as clean_worker_registry, get_keys as get_keys
from typing import Any, Optional, Callable, Type, List, Iterable, Sequence

green: Callable[[str], str]
yellow: Callable[[str], str]
blue: Callable[[str], str]
logger: Logger

class StopRequested(Exception): ...

def compact(l: Any): ...

_signames: Any

def signal_name(signum: Any): ...

WorkerStatus: Any

class Worker:
    redis_worker_namespace_prefix: str = ...
    redis_workers_keys: Sequence[str] = ...
    death_penalty_class: Type[BaseDeathPenalty] = ...
    queue_class: Type[Queue] = ...
    job_class: Type[Job] = ...
    log_result_lifespan: bool = ...
    log_job_description: bool = ...
    connection: Redis = ...
    redis_server_version: Any = ...

    name: str = ...
    hostname: Optional[str] = ...
    pid: Optional[int] = ...
    version: Any = ...
    python_version: Any = ...
    serializer: DefaultSerializer = ...
    queues: List[Queue] = ...
    default_result_ttl: Optional[int] = ...
    default_worker_ttl: Optional[int] = ...
    job_monitoring_interval: int = ...
    log: logging.Logger = ...

    last_cleaned_at: Any = ...
    successful_job_count: int = ...
    failed_job_count: int = ...
    total_working_time: float = ...
    birth_date: datetime.datetime = ...
    scheduler: RQScheduler = ...
    disable_default_exception_handler: bool = ...

    state: Any = ...

    _exc_handlers: Any = ...
    _state: str = ...
    _is_horse: bool = ...
    _horse_pid: int = ...
    _stop_requested: bool = ...
    _job_id: Optional[str] = ...
    last_heartbeat: Any = ...
    @classmethod
    def all(
        cls,
        connection: Optional[Redis] = ...,
        job_class: Optional[Type[Job]] = ...,
        queue_class: Optional[Type[Queue]] = ...,
        queue: Optional[Queue] = ...,
        serializer: Optional[DefaultSerializer] = ...,
    ): ...
    @classmethod
    def all_keys(cls, connection: Optional[Any] = ..., queue: Optional[Any] = ...): ...
    @classmethod
    def count(cls, connection: Optional[Any] = ..., queue: Optional[Any] = ...): ...
    @classmethod
    def find_by_key(
        cls,
        worker_key: Any,
        connection: Optional[Any] = ...,
        job_class: Optional[Any] = ...,
        queue_class: Optional[Any] = ...,
        serializer: Optional[Any] = ...,
    ): ...
    def __init__(
        self,
        queues: Iterable[Queue],
        name: Optional[str] = ...,
        default_result_ttl: int = ...,
        connection: Optional[Redis] = ...,
        exc_handler: Optional[Any] = ...,
        exception_handlers: Optional[Any] = ...,
        default_worker_ttl: int = ...,
        job_class: Optional[Type[Job]] = ...,
        queue_class: Optional[Type[Queue]] = ...,
        log_job_description: bool = ...,
        job_monitoring_interval: int = ...,
        disable_default_exception_handler: bool = ...,
        prepare_for_work: bool = ...,
        serializer: Optional[DefaultSerializer] = ...,
    ) -> None: ...
    def get_redis_server_version(self): ...
    def validate_queues(self) -> None: ...
    def queue_names(self) -> List[str]: ...
    def queue_keys(self) -> List[str]: ...
    @property
    def key(self) -> str: ...
    @property
    def horse_pid(self) -> Optional[int]: ...
    @property
    def is_horse(self) -> bool: ...
    def procline(self, message: Any) -> None: ...
    def register_birth(self) -> None: ...
    def register_death(self) -> None: ...
    def set_shutdown_requested_date(self) -> None: ...
    @property
    def shutdown_requested_date(self): ...
    @property
    def death_date(self): ...
    def set_state(self, state: str, pipeline: Optional[Pipeline] = ...) -> None: ...
    def _set_state(self, state: str) -> None: ...
    def get_state(self) -> str: ...
    def _get_state(self) -> str: ...
    def set_current_job_id(self, job_id: Optional[str], pipeline: Optional[Pipeline] = ...) -> None: ...
    def get_current_job_id(self, pipeline: Optional[Pipeline] = ...) -> Optional[str]: ...
    def get_current_job(self) -> Optional[Job]: ...
    def _install_signal_handlers(self) -> None: ...
    def kill_horse(self, sig: Any = ...) -> None: ...
    def wait_for_horse(self): ...
    def request_force_stop(self, signum: Any, frame: Any) -> None: ...
    def request_stop(self, signum: Any, frame: Any) -> None: ...
    def handle_warm_shutdown_request(self) -> None: ...
    def check_for_suspension(self, burst: bool) -> None: ...
    def run_maintenance_tasks(self) -> None: ...
    def work(
        self,
        burst: bool = ...,
        logging_level: str = ...,
        date_format: str = ...,
        log_format: str = ...,
        max_jobs: Optional[int] = ...,
        with_scheduler: bool = ...,
    ): ...
    def stop_scheduler(self) -> None: ...
    def dequeue_job_and_maintain_ttl(self, timeout: Optional[int]): ...
    def heartbeat(self, timeout: Optional[int] = ..., pipeline: Optional[Pipeline] = ...) -> None: ...
    def refresh(self) -> None: ...
    def increment_failed_job_count(self, pipeline: Optional[Pipeline] = ...) -> None: ...
    def increment_successful_job_count(self, pipeline: Optional[Pipeline] = ...) -> None: ...
    def increment_total_working_time(self, job_execution_time: Any, pipeline: Pipeline) -> None: ...
    def fork_work_horse(self, job: Job, queue: Queue) -> None: ...
    def monitor_work_horse(self, job: Job, queue: Queue) -> None: ...
    def execute_job(self, job: Job, queue: Queue) -> None: ...
    def main_work_horse(self, job: Job, queue: Queue) -> None: ...
    def setup_work_horse_signals(self) -> None: ...
    def prepare_job_execution(self, job: Job, heartbeat_ttl: Optional[Any] = ...) -> None: ...
    def handle_job_failure(
        self, job: Job, queue: Queue, started_job_registry: Optional[StartedJobRegistry] = ..., exc_string: str = ...
    ) -> None: ...
    def handle_job_success(self, job: Job, queue: Queue, started_job_registry: StartedJobRegistry) -> None: ...
    def perform_job(self, job: Job, queue: Queue, heartbeat_ttl: Optional[int] = ...): ...
    def handle_exception(self, job: Job, *exc_info: Any) -> None: ...
    @staticmethod
    def _get_safe_exception_string(exc_strings: Any): ...
    def push_exc_handler(self, handler_func: Any) -> None: ...
    def pop_exc_handler(self): ...
    def __eq__(self, other: Any) -> Any: ...
    def __hash__(self) -> Any: ...
    def clean_registries(self) -> None: ...
    @property
    def should_run_maintenance_tasks(self) -> bool: ...

class SimpleWorker(Worker):
    def main_work_horse(self, *args: Any, **kwargs: Any) -> None: ...
    def execute_job(self, job: Job, queue: Queue): ...

class HerokuWorker(Worker):
    imminent_shutdown_delay: int = ...
    frame_properties: Any = ...
    def setup_work_horse_signals(self) -> None: ...
    def handle_warm_shutdown_request(self) -> None: ...
    def request_stop_sigrtmin(self, signum: Any, frame: Any) -> None: ...
    def request_force_stop_sigrtmin(self, signum: Any, frame: Any) -> None: ...
